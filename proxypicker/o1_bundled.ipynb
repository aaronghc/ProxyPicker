{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-25T10:23:51.732807Z",
     "start_time": "2025-02-25T10:23:51.730284Z"
    }
   },
   "source": [
    "# source proxypicker-env/bin/activate\n",
    "# \n",
    "# cd /Users/jamaman/Documents/GitHub/ProxyPicker/images\n",
    "# \n",
    "# python3 -m http.server\n",
    "# "
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T10:24:00.203859Z",
     "start_time": "2025-02-25T10:23:51.737253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, getpass\n",
    "import operator\n",
    "import base64\n",
    "\n",
    "import httpx\n",
    "from typing import Optional\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.constants import Send\n",
    "from IPython.display import Image\n",
    "from langgraph.graph import END, StateGraph, START, MessagesState\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ],
   "id": "c928d348942d5a8f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T10:24:00.368875Z",
     "start_time": "2025-02-25T10:24:00.295269Z"
    }
   },
   "cell_type": "code",
   "source": "proxy_picker_llm = ChatOpenAI(model=\"o1-2024-12-17\")",
   "id": "66999abf35bd2d0e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T10:24:00.374427Z",
     "start_time": "2025-02-25T10:24:00.372960Z"
    }
   },
   "cell_type": "code",
   "source": "# proxy_picker_llm = ChatOpenAI(model=\"gpt-4\", temperature=0.1, base_url=\"https://reverse.onechats.top/v1\")",
   "id": "516dce0a9464693b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T10:24:19.048039Z",
     "start_time": "2025-02-25T10:24:00.379002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "_set_env(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"proxy_picker\""
   ],
   "id": "33926c4cf01d0f70",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T10:24:19.301153Z",
     "start_time": "2025-02-25T10:24:19.053456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "physical_url01 = \"http://localhost:8000/s1.jpg\"\n",
    "image_data01 = base64.b64encode(httpx.get(physical_url01).content).decode(\"utf-8\")\n",
    "physical_url02 = \"http://localhost:8000/p36.jpg\"\n",
    "image_data02 = base64.b64encode(httpx.get(physical_url02).content).decode(\"utf-8\")\n",
    "physical_url03 = \"http://localhost:8000/p6.jpg\"\n",
    "image_data03 = base64.b64encode(httpx.get(physical_url03).content).decode(\"utf-8\")\n",
    "prefab_url01 = \"http://localhost:8000/f30.jpg\"\n",
    "prefab_data01 = base64.b64encode(httpx.get(prefab_url01).content).decode(\"utf-8\")\n",
    "prefab_url02 = \"http://localhost:8000/f31.jpg\"\n",
    "prefab_data02 = base64.b64encode(httpx.get(prefab_url02).content).decode(\"utf-8\")\n",
    "prefab_url03 = \"http://localhost:8000/f29.jpg\"\n",
    "prefab_data03 = base64.b64encode(httpx.get(prefab_url03).content).decode(\"utf-8\")"
   ],
   "id": "e2842cc259d76024",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T10:24:19.311708Z",
     "start_time": "2025-02-25T10:24:19.308058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt_system = SystemMessage(content=\"\"\"You are a haptic proxy picker. Your primary goal is to select suitable physical proxies from the images of the real-world surroundings of a VR user so that the user experiences the intended haptic feedback when interacting with target virtual objects.\n",
    "\n",
    "Annotation of Input Information:\n",
    "    -VR Activity: Describes the scenario and overall purpose of the target virtual objects.\n",
    "    -Target Virtual Objects: The items in the VR scene for which you must propose haptic proxies. \n",
    "    -Highly Expected Haptic Feedback from Direct Contact: Feedback that the VR developer deems essential when the user's body directly touches or grasps the virtual object.\n",
    "    -Highly Expected Haptic Feedback from Interaction Pairs: Feedback deemed critical when multiple virtual objects collide or interact (e.g., a ball being struck by a bat).\n",
    "    -Images of Surrounding Physical Objects: Depictions of the user’s real-world environment, showing what potential proxies are available. \n",
    "    -Images of Virtual Objects: Snapshots or 3D renders of the virtual objects needing proxies.\n",
    "\n",
    "Proxy Picking Instructions:\n",
    "    1. Base Your Decisions on the Provided Data\n",
    "        *Construct the interaction scenario and anticipate the expected haptic feedback by reviewing the provided images, text descriptions, and usage instructions.\n",
    "        *Then, think in reverse: envision which physical proxies from the environment can supply the needed haptic sensations.\n",
    "    2. Think Differently by Contact Type\n",
    "        *Direct Contact Objects\n",
    "            -These are virtual objects the user's body directly contacts (e.g., tennis racket, shovel, chair)\n",
    "            -Strive for close matching across key haptic dimensions (shape, weight, texture, hardness), because contact is immediate.\n",
    "            -If “highly expected haptic feedback” is specified, prioritize simulating those properties.\n",
    "        *Tool-Mediated Objects\n",
    "            -These objects interact with the user indirectly via another tool (e.g., a golf ball being struck by a club).\n",
    "            -Be more flexible and creative when picking a proxy, as long as the user perceives the correct collisions, vibrations or force through the direct contact tool (e.g., a christmas tree could be a haptic proxy of a ping pang ball since the bat normally end up colliding with the tree with every swing; the scissors placed in a pen holder can serve as the haptic proxy for the lock when simulating the feedback of prying the lock open with a crowbar).\n",
    "    3. Choose with Focus\n",
    "        *\"Highly expected haptic feedback\" indicates which properties are especially prioritized by the VR developer. Although you should consider every property that might matter for immersion, prioritize these highlighted properties first if there is a trade-off.\n",
    "        *A \"no further expectation\" means there is no specific emphasis from the developer--however, you must still propose a proxy for that virtual object.\n",
    "    4. Consider Multi-Object Interactions\n",
    "        *Deduce the mentioned interaction pairs and how they might physically collide, transfer, interact with and so on.\n",
    "        *Think carefully about any haptic feedback that arises from these interactions.\n",
    "    \n",
    "Final Output Requirements: \n",
    "    1. Assign the most suitable physical object to each target virtual object (one proxy per virtual item).\n",
    "    2. Specify the location of each chosen haptic proxy (i.e., where it is found in the provided images)\n",
    "    3. Justify your proxy selection for each virtual object.\n",
    "    4. Describe how to hold or manipulate the chosen proxies so it simulate the expected haptic feedback.\"\"\")\n",
    "\n",
    "prompt_human = HumanMessage(content=[\n",
    "    {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": \"\"\"\n",
    "        VR Activity: hair dressing\n",
    "        \n",
    "        Target Virtual Objects: \n",
    "            *tail comb (Direct Contact Objects)\n",
    "            *hairbrush (Direct Contact Objects)\n",
    "            *hair clipper (Direct Contact Objects)\n",
    "            *folding razor (Direct Contact Objects)\n",
    "            *scissors (Direct Contact Objects)\n",
    "            *handheld mirror (Direct Contact Objects)\n",
    "            *man with short hair (Tool-Mediated Objects)\n",
    "            \n",
    "        Highly Expected Haptic Feedback from Direct Contact:\n",
    "            *tail comb: its thin and fine tail\n",
    "            *hairbrush: overall grasping shape\n",
    "            *hair clipper: the shape where grasp; a switch button; slightly heavy weight\n",
    "            *folding razor: foldable mechanism\n",
    "            *scissors: flexible hinge that can be driven by two fingers\n",
    "            *handheld mirror: its two handles \n",
    "            *hair: no further expectation\n",
    "            \n",
    "        Highly Expected Haptic Feedback from Interaction Pairs:\n",
    "            *man with short hair--folding razor: counter-acting soft force when contacting；soft scraping sensation of trimming hair\n",
    "\n",
    "    \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": \"image(s) of surrounding physical objects:\",\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data01}\", \"detail\": \"high\"},\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data02}\", \"detail\": \"high\"},\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data03}\", \"detail\": \"high\"},\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": \"image of virtual object:\",\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{prefab_data01}\", \"detail\": \"high\"},\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{prefab_data02}\", \"detail\": \"high\"},\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{prefab_data03}\", \"detail\": \"high\"},\n",
    "    },\n",
    "])\n",
    "\n",
    "msgs = [prompt_system, prompt_human]"
   ],
   "id": "f258c3daeb7f74d2",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T10:27:05.171170Z",
     "start_time": "2025-02-25T10:24:19.336383Z"
    }
   },
   "cell_type": "code",
   "source": "proxy_picker_llm.invoke(msgs)",
   "id": "e0a86da7c14c269c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='1) Tail Comb → The thin green pencil on the desk.  \\n   • Location: In the pencil holder or lying on the desktop in the first image.  \\n   • Rationale: The pencil’s long, slim shaft mimics the fine‐tail of the comb; you can “part” and “section” hair in VR by using the pencil as if it were the comb’s narrow tip.  \\n   • Usage: Hold it exactly as you would a tail comb—pinched near the tip for detail work or by the writing end for longer strokes.  \\n\\n2) Hairbrush → The cylindrical metal pen cup on the left side of the desk.  \\n   • Location: On the wooden desk in the first image, where the pens and pencils are stored.  \\n   • Rationale: While it lacks bristles, it provides a similarly sized object to grip, approximating the “overall grasping shape” of a hairbrush’s handle and body.  \\n   • Usage: Wrap your fingers around it as though gripping a brush handle and move it in brushing motions against the “hair.”  \\n\\n3) Hair Clipper → The small stereo or CD‐player remote in the third image.  \\n   • Location: Lying atop or near the small stereo system (the yellow desk in the third photo).  \\n   • Rationale: It has a handheld form, a bit of weight, and real buttons (especially a power button), which closely match the feel of flipping a hair‐clipper switch and hefting its body.  \\n   • Usage: Grasp it in the palm as if it were the clipper, pressing the actual remote buttons to mimic toggling the clipper’s switch.  \\n\\n4) Folding Razor → The black stapler on the first desk.  \\n   • Location: On the desktop next to the tissue box (first image).  \\n   • Rationale: A stapler can be “folded open” on its hinge, loosely imitating the folding action of a barber’s razor.  \\n   • Usage: Hold the stapler in one hand and open its arm when you’d “unfold the razor,” then close it again to stow it.  \\n\\n5) Scissors → The real scissors in the pencil holder (first image).  \\n   • Location: In the cylindrical pen cup on the first desk.  \\n   • Rationale: They already have a proper hinge and are driven by two fingers, exactly what’s needed to replicate the VR scissors’ “flexible hinge.”  \\n   • Usage: Slip your thumb and finger into the loops just as you would normal scissors, and squeeze for the cutting action as the VR scissors.  \\n\\n6) Handheld Mirror → The white plastic bin with two cut‐out handles (second image).  \\n   • Location: On the shelf below the red football helmet.  \\n   • Rationale: The bin’s rectangular shape and two side grips replicate the mirror’s “two‐handle” form.  \\n   • Usage: Grip each handle on either side and lift it up toward where you’d expect the user’s face or hairline to be, as if you were angling a handheld mirror.  \\n\\n7) Man with Short Hair → One of the soft baseball caps (second image).  \\n   • Location: Hanging with the other caps on the wall rack in the same photo as the batting helmet.  \\n   • Rationale: Pressing the folding razor (the stapler) or “brush” (the pen cup) into the soft fabric can simulate the slight give of short hair and scalp.  \\n   • Usage: Hold or prop the cap so that when the razor “contacts” it, you feel a gentle resistance and a soft “scraping” friction to mirror trimming hair.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 3894, 'prompt_tokens': 5706, 'total_tokens': 9600, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 3008, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 4992}}, 'model_name': 'o1-2024-12-17', 'system_fingerprint': 'fp_60442b0df0', 'finish_reason': 'stop', 'logprobs': None}, id='run-998f58fd-6b78-4d0c-8c99-5b080822acf9-0', usage_metadata={'input_tokens': 5706, 'output_tokens': 3894, 'total_tokens': 9600, 'input_token_details': {'audio': 0, 'cache_read': 4992}, 'output_token_details': {'audio': 0, 'reasoning': 3008}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
