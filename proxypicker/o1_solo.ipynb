{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-20T16:37:32.500695Z",
     "start_time": "2025-02-20T16:37:32.494905Z"
    }
   },
   "source": [
    "# source proxypicker-env/bin/activate\n",
    "# \n",
    "# cd /Users/jamaman/Documents/GitHub/ProxyPicker/images\n",
    "# \n",
    "# python3 -m http.server\n",
    "# "
   ],
   "outputs": [],
   "execution_count": 149
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T16:37:32.509732Z",
     "start_time": "2025-02-20T16:37:32.506600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, getpass\n",
    "import operator\n",
    "import base64\n",
    "\n",
    "import httpx\n",
    "from typing import Optional\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.constants import Send\n",
    "from IPython.display import Image\n",
    "from langgraph.graph import END, StateGraph, START, MessagesState\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ],
   "id": "c928d348942d5a8f",
   "outputs": [],
   "execution_count": 150
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T16:37:32.602679Z",
     "start_time": "2025-02-20T16:37:32.518382Z"
    }
   },
   "cell_type": "code",
   "source": "proxy_picker_llm = ChatOpenAI(model=\"o1-2024-12-17\")",
   "id": "66999abf35bd2d0e",
   "outputs": [],
   "execution_count": 151
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T16:37:32.616318Z",
     "start_time": "2025-02-20T16:37:32.614875Z"
    }
   },
   "cell_type": "code",
   "source": "# proxy_picker_llm = ChatOpenAI(model=\"gpt-4\", temperature=0.1, base_url=\"https://reverse.onechats.top/v1\")",
   "id": "516dce0a9464693b",
   "outputs": [],
   "execution_count": 152
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T16:37:32.623860Z",
     "start_time": "2025-02-20T16:37:32.622380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "_set_env(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"proxy_picker\""
   ],
   "id": "33926c4cf01d0f70",
   "outputs": [],
   "execution_count": 153
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T16:37:32.789755Z",
     "start_time": "2025-02-20T16:37:32.629980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "physical_url01 = \"http://localhost:8000/p6.jpg\"\n",
    "image_data01 = base64.b64encode(httpx.get(physical_url01).content).decode(\"utf-8\")\n",
    "physical_url02 = \"http://localhost:8000/s5.jpg\"\n",
    "image_data02 = base64.b64encode(httpx.get(physical_url02).content).decode(\"utf-8\")\n",
    "physical_url03 = \"http://localhost:8000/s6.jpg\"\n",
    "image_data03 = base64.b64encode(httpx.get(physical_url03).content).decode(\"utf-8\")\n",
    "prefab_url = \"http://localhost:8000/f15.jpg\"\n",
    "prefab_data = base64.b64encode(httpx.get(prefab_url).content).decode(\"utf-8\")"
   ],
   "id": "e2842cc259d76024",
   "outputs": [],
   "execution_count": 154
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T16:37:32.797859Z",
     "start_time": "2025-02-20T16:37:32.796427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def assistant(state: MessagesState):\n",
    "#     prompt_system = SystemMessage(content=\"You are a haptic proxy picker, please choose a physical object from the given picture as the most suitable haptic proxy for the given task in virtual reality. The image for the target virtual object may also be provided.\")\n",
    "#     prompt_human = HumanMessage(content=[\n",
    "#         {\n",
    "#             \"type\": \"text\",\n",
    "#             \"text\": \"driving\",\n",
    "#         },\n",
    "#         {\n",
    "#             \"type\": \"text\",\n",
    "#             \"text\": \"image(s) of surrounding objects:\",\n",
    "#         },\n",
    "#         {\n",
    "#             \"type\": \"image_url\",\n",
    "#             \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data01}\"},\n",
    "#         },\n",
    "#         {\n",
    "#             \"type\": \"text\",\n",
    "#             \"text\": \"image of interacted virtual object:\",\n",
    "#         },\n",
    "#         {\n",
    "#             \"type\": \"image_url\",\n",
    "#             \"image_url\": {\"url\": f\"data:image/jpeg;base64,{prefab_data01}\"},\n",
    "#         }\n",
    "#     ])"
   ],
   "id": "169c5dbb0b778d69",
   "outputs": [],
   "execution_count": 155
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T16:37:32.806557Z",
     "start_time": "2025-02-20T16:37:32.804047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt_system = SystemMessage(content=\"\"\"You are a haptic proxy picker, please choose top three physical objects from the given images of surrounding physical objects as the most suitable haptic proxies for the virtual object. The context is described as follow:\n",
    "    1. The given task: illuminating\n",
    "    2. Target virtual objects: torch\n",
    "    3. Highly expected haptic feedback from virtual object: shape of holding part; wood texture\n",
    "\n",
    "Proxy Picking Instructions:\n",
    "    1. Base Your Decisions on the Provided Data\n",
    "        *Refer to the given images of virtual and physical objects, as well as any written context and usage descriptions for expected haptic feedback\n",
    "        *When picking a haptic proxy, think about shape, texture, hardness, temperature, weight, interactivity\n",
    "    2. Choose with Focus\n",
    "        *\"Highly expected haptic feedback\" indicates which properties are especially prioritized by the VR developer. Although you should consider every property that might matter for immersion, prioritize these highlighted properties first if there is a trade-off.\n",
    "        *A \"no further expectation\" means there is no specific emphasis from the developer--however, you must still propose a proxy for that virtual object.\n",
    "    \n",
    "Final Output Requirements: \n",
    "    1. Find the top three most suitable candidate among the physical objects for the target virtual object.\n",
    "    2. Rank them based on their suitability. \n",
    "    2. Justify your proxy selection for the three proxy candidates.\n",
    "    3. Explain how to hold or use each selected physical object so it simulate the expected haptic feedback.\"\"\")\n",
    "prompt_human = HumanMessage(content=[\n",
    "    {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": \"image(s) of surrounding physical objects:\",\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data01}\", \"detail\": \"high\"},\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data02}\", \"detail\": \"high\"},\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data03}\", \"detail\": \"high\"},\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": \"image of virtual object:\",\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{prefab_data}\", \"detail\": \"high\"},\n",
    "    }\n",
    "])\n",
    "msgs = [prompt_system, prompt_human]"
   ],
   "id": "8ac56a1941ab9899",
   "outputs": [],
   "execution_count": 156
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T16:37:32.812557Z",
     "start_time": "2025-02-20T16:37:32.811156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# prompt_system = SystemMessage(content=\"You are a haptic proxy picker, please choose top three physical objects from the given picture as the most suitable haptic proxies for the given task in virtual reality. Rank them based on their suitability. You should list all the recognizable physical objects from the given picture first. The image for the target virtual object may also be provided. \\n The given task: hugging the pot and moving to another place. \\n The target virtual object: a pot of plant. \\n Highly expected haptic feedbacks: the outline of grabbed or held area; matched weight\")\n",
    "# prompt_human = HumanMessage(content=[\n",
    "#     {\n",
    "#         \"type\": \"text\",\n",
    "#         \"text\": \"image(s) of surrounding physical objects:\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"type\": \"image_url\",\n",
    "#         \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data01}\", \"detail\": \"high\"},\n",
    "#     },\n",
    "#     {\n",
    "#         \"type\": \"image_url\",\n",
    "#         \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data02}\", \"detail\": \"high\"},\n",
    "#     },\n",
    "#     {\n",
    "#         \"type\": \"image_url\",\n",
    "#         \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data03}\", \"detail\": \"high\"},\n",
    "#     },\n",
    "#     {\n",
    "#         \"type\": \"text\",\n",
    "#         \"text\": \"image of virtual object:\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"type\": \"image_url\",\n",
    "#         \"image_url\": {\"url\": f\"data:image/jpeg;base64,{prefab_data}\", \"detail\": \"high\"},\n",
    "#     }\n",
    "# ])\n",
    "# msgs = [prompt_system, prompt_human]"
   ],
   "id": "99605c452b661a69",
   "outputs": [],
   "execution_count": 157
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T16:38:19.985767Z",
     "start_time": "2025-02-20T16:37:32.817880Z"
    }
   },
   "cell_type": "code",
   "source": "proxy_picker_llm.invoke(msgs)",
   "id": "e0a86da7c14c269c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='1) A carved wooden statuette (on top of the speaker).  \\n   • Why Picked: It appears to be solid wood with a hand‐carved feel; the narrow lower portion can serve as a handle while the top portion simulates a torch head. This directly provides the “wood texture” and a roughly “torch‐like” shape.  \\n   • How to Hold/Use: Grasp it by the narrow end (as if it were the bottom of the torch shaft) so that the thicker, sculpted top imitates the torch’s head.\\n\\n2) The neck of the standing wooden‐bodied guitar.  \\n   • Why Picked: The back of the guitar neck is smoothly curved, wooden, and long enough to simulate the sensation of holding a torch shaft. Although it is lacquered, it still provides a firm wooden feel.  \\n   • How to Hold/Use: Gently wrap one hand around the neck (taking care not to apply pressure to the strings), keeping the headstock pointed upward to mimic the torch’s lit end.\\n\\n3) The small wooden speaker box on the desk.  \\n   • Why Picked: Despite a more boxy profile, it still has a definite wooden exterior. If gripped around one end, it can stand in as a rigid wooden “handle.”  \\n   • How to Hold/Use: Grip one side firmly with the speaker oriented vertically, so the top (where the speaker mesh is) becomes the “torch head.”', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1848, 'prompt_tokens': 1309, 'total_tokens': 3157, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1536, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'o1-2024-12-17', 'system_fingerprint': 'fp_067fc2f631', 'finish_reason': 'stop', 'logprobs': None}, id='run-0a6a961d-d2d0-4782-9df5-7037ab4ee038-0', usage_metadata={'input_tokens': 1309, 'output_tokens': 1848, 'total_tokens': 3157, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1536}})"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 158
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
